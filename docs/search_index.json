[
["index.html", "Essential R Abstract", " Essential R Simon Dirmeier 2018-10-05 Abstract The lyf so short, the craft so long to lerne. – Geoffrey Chaucer This book serves as a collection of tools for package development, good practices for programming, and my most frequently used packages. The material treated here certainly does not cover all of R, but rather serves as my personal list of essential things related to programming in R that I found useful to know. The document is partly opinionated and subjective, so feel free to open up an issue if you feel some parts should be clarified or reformulated. The book is no introduction on how to program functionally, procedurally or in an object-oriented way, how to write code in general, or how to speed it up. The interested reader is referred to: Robert Martin: Clean Code, Andrew Hunt: The Pragmatic Programmer, Gang of Four: Design Patterns, Colin Gillespie: Efficient R programming, Patrick Burns: The R Inferno, Hadley Wickham: R packages, Hadley Wickham: Advanced R, Dirk Eddelbuettel: Seamless R and C++ Integration with Rcpp, Thomas Cormen: Introduction to Algorithms, Dan Gusfield: Algorithms on Strings, Trees and Sequences, Donald Knuth: The Art of Computer Programming, a comment by Peter Norvig, … "],
["r-package-development.html", "1 R package development 1.1 Creating R packages 1.2 Writing R packages 1.3 Testing code 1.4 Documenting code 1.5 Checking code 1.6 Static code analysis 1.7 Code coverage 1.8 Profiling and benchmarking 1.9 Creating a landing page", " 1 R package development The following section covers tools that help and speed up developing R 1.1 Creating R packages A minimum R-package stack at least consists of the following packages of tools: yeoman devtools testthat roxygen2 covr lintr usethis If you have yeoman installed, you can use the R-bones generator in order to initialize a complete project. This gives you the following barebone: yo r-bones ls -la pkg total 1624 drwxr-xr-x 26 simondi 1029 832 Jan 26 2018 . drwxr-xr-x 31 simondi 1029 992 Oct 5 23:34 .. -rw-r--r-- 1 simondi 1029 220 Jan 22 2018 .Rbuildignore drwxr-xr-x 4 simondi 1029 128 Jan 23 2018 .Rproj.user -rw-r--r-- 1 simondi 1029 410 Jan 22 2018 .codecov.yml -rw-r--r-- 1 simondi 1029 51 Jan 22 2018 .gitattributes -rw-r--r-- 1 simondi 1029 421 Jan 22 2018 .gitignore -rw-r--r-- 1 simondi 1029 556 Jan 22 2018 .lintr -rw-r--r-- 1 simondi 1029 829 Jan 23 2018 .travis.yml -rw-r--r-- 1 simondi 1029 176 Jan 22 2018 .yo-rc.json -rw-r--r-- 1 simondi 1029 548 Jan 23 2018 DESCRIPTION -rw-r--r-- 1 simondi 1029 35141 Jan 22 2018 LICENSE -rw-r--r-- 1 simondi 1029 56 Jan 23 2018 NAMESPACE drwxr-xr-x 4 simondi 1029 128 Jan 23 2018 R -rw-r--r-- 1 simondi 1029 556 Jan 24 2018 README.md -rw-r--r-- 1 simondi 1029 93 Jan 22 2018 TODO.md -rw-r--r-- 1 simondi 1029 136 Jan 22 2018 VERSIONS.md -rw-r--r-- 1 simondi 1029 885 Jan 26 2018 appveyor.yml drwxr-xr-x 11 simondi 1029 352 Jan 24 2018 docs drwxr-xr-x 3 simondi 1029 96 Jan 22 2018 inst drwxr-xr-x 3 simondi 1029 96 Jan 23 2018 man -rw-r--r-- 1 simondi 1029 354 Jan 24 2018 newpkg.Rproj -rw-r--r-- 1 simondi 1029 736082 Jan 23 2018 newpkg.html drwxr-xr-x 2 simondi 1029 64 Jan 23 2018 src drwxr-xr-x 4 simondi 1029 128 Jan 22 2018 tests drwxr-xr-x 3 simondi 1029 96 Jan 22 2018 vignettes 1.2 Writing R packages When creating an R package devtools and covr cover almost any functionality required. The following functions delineate how my typical workflow looks: devtools::create(&quot;pkg&quot;) devtools::use_rcpp() devtools::document() devtools::test() devtools::check_cran() devtools::lint() devtools::run_examples() covr::package_coverage() devtools::install() This basically covers your complete development life cycle. devtools is tremendously useful. If you look for something that helps you write a package, devtools usually has a function for it. For all other things, use usethis. usethis::use_namespace() usethis::use_code_of_conduct() usethis::use_travis() usethis::use_vignette() usethis::use_gpl3_license() 1.3 Testing code Right after creating your package, you should write your first test (yes, really). Testing is essential*for writing good software. The same way as programming languages change your way of thinking, unit tests change your way of writing functions. testthat is probably the best way to go here. Tests are usually put in tests/testthat. You can use: devtools::use_testthat() to create a test suite automatically. A test would look like this: testthat::test_that(&quot;i know my math&quot;, { testthat::expect_equal(g(), 2) }) testthat::test_that(&quot;i know my math&quot;, { testthat::expect_false(&quot;wrong&quot; == &quot;right&quot;) }) Let’s test this. devtools::test(&quot;./pkg&quot;) ✔ | OK F W S | Context ⠏ | 0 | hello ⠋ | 1 | hello ⠙ | 2 | hello ✔ | 2 | hello ══ Results ════════════════════════════════════════════════════════════════ Duration: 0.1 s OK: 2 Failed: 0 Warnings: 0 Skipped: 0 A function ideally does one task and one task only. Functions with side effects, multiple operations or exceedingly large method body easily introduce bugs. Keep your functions concise! This also simplifies testing, because it is easier to track down a bug in a shorter function. 1.4 Documenting code Having written the first unit test, we can create the actual function and its respective documentation using roxygen2: #&#39; @title Adds 1 and 1 #&#39; #&#39; @description This magnificent function computes the sum of 1 and 1. #&#39; #&#39; @export #&#39; #&#39; @return returns 2 #&#39; #&#39; @examples #&#39; a &lt;- g() #&#39; print(a) g &lt;- function() 1 + 1 Then build the documentation: devtools::document(&quot;./pkg&quot;) An excellent help for creating documentation (of S3 and S4) is for instance pckdev or the official vignette. 1.5 Checking code If you want to submit your package to CRAN or Bioconductor certain criteria must be fulfilled. Some of which can be tested by checking or package like this: devtools::check_cran(&quot;./pkg&quot;) Checking 1 CRAN packages ================================================= Results saved in /var/folders/cx/v45t2v2n6b548_vfn76vnzlw0050sr/T//RtmpGFUnp3/check_cran183ee63c2fa0b Package library: /private/var/folders/cx/v45t2v2n6b548_vfn76vnzlw0050sr/T/RtmpGFUnp3/R-lib, /Library/Frameworks/R.framework/Versions/3.5/Resources/library Installing dependencies -------------------------------------------------- Installing 1 packages: ./pkg Skipping 1 packages without source:./pkg Checking packages -------------------------------------------------------- Checking 0 packages: Package library: /private/var/folders/cx/v45t2v2n6b548_vfn76vnzlw0050sr/T/RtmpGFUnp3/R-lib, /Library/Frameworks/R.framework/Versions/3.5/Resources/library NULL This does not test for Bioconductor though. For this you have to install BioCheck manually and call R CMD BiocCheck newpkg*.tar on the command line. 1.6 Static code analysis lintr checks your code for style, syntax error and possible issues. You can also incorporate lintr in your unit tests and let them fail, if lints are discovered. if (requireNamespace(&quot;lintr&quot;, quietly = TRUE)) { test_that(&quot;this is lint free&quot;, { lintr::expect_lint_free() }) } What lintr considers worth reporting can be customized in a .lintr file in your package root directory. Let’s see if our small package is lint free: devtools::lint(&quot;./pkg&quot;) Linting newpkg R/bad_bad_file.R:3:1: style: lines should not be more than 80 characters. myRet = a+b ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ R/bad_bad_file.R:3:79: style: Variable and function names should be all lowercase. myRet = a+b ^~~~~ R/bad_bad_file.R:3:85: style: Use &lt;-, not =, for assignment. myRet = a+b ^ Whoops! 1.6.1 Running examples Examples are extremely helpful both for the user and debugging purposes. When we documented our function g we already have an example how to use the function. We can manually call all examples using: devtools::run_examples(&quot;./pkg&quot;) Updating newpkg documentation Loading newpkg Running 1 example files in newpkg ---------------------------------------- Loading newpkg Running examples in g.Rd ------------------------------------------------- &gt; &gt; a &lt;- g() &gt; print(a) [1] 2 Loading newpkg 1.7 Code coverage covr lets you check how much of your code is used and tested. If you created a package just run: covr::package_coverage(&quot;./pkg&quot;) newpkg Coverage: 50.00% R/bad_bad_file.R: 0.00% R/newpkg.R: 100.00% Having high code coverage usually correlates with a good testing suite. The more functionality is tested, the larger the code coverage. You can customized reports by adding a file called .codecov.yml to your project’s root: cat ./pkg/.codecov.yml comment: behavior: default layout: header, diff require_changes: false coverage: precision: 2 range: - 70.0 - 100.0 round: down status: changes: false patch: true project: true parsers: gcov: branch_detection: conditional: true loop: true macro: false method: false javascript: enable_partials: false ignore: - &quot;inst/include/&quot; - &quot;inst/&quot; 1.8 Profiling and benchmarking If you think your code runs slowly, you can try to find the bottleneck, for instance, using profvis and microbenchmark. library(&quot;profvis&quot;) library(&quot;ggthemes&quot;) library(&quot;gam&quot;) data(kyphosis) profvis::profvis({ sp &lt;- stats::spline(kyphosis$Age, kyphosis$Number, method = &quot;n&quot;) gm &lt;- gam::gam(Number ~ Age, family = poisson, data = kyphosis) df &lt;- data.frame(X = c(sp$x, kyphosis$Age), Y = c(sp$y, predict(gm, kyphosis)), model = c(rep(&quot;Spline&quot;, length(sp$x)), rep(&quot;GAM&quot;, length(kyphosis$Age)))) g &lt;- ggplot2::ggplot(df) + ggplot2::geom_point(ggplot2::aes(x = X, y = Y, color = model)) + ggthemes::theme_tufte() print(g) }) Often it however suffices to just benchmark two methods against each other. f &lt;- function(n) { sum &lt;- 0 for (i in seq(n)) sum &lt;- sum + i } g &lt;- function(.) sum(.) microbenchmark::microbenchmark(f(10000), g(10000)) Unit: nanoseconds expr min lq mean median uq max neval cld f(10000) 338879 618898.0 735239.4 657789.5 725094.5 4801710 100 b g(10000) 414 839.5 18189.7 1475.5 5056.5 1446777 100 a 1.9 Creating a landing page At this point you are finished writing your package and you want to provide it to a large user base. A nice landing page often helps gaining popularity. The easiest way to do so is using pkgdown. pkgdown::build_site(pkg = &quot;./pkg&quot;) This creates a web-page like this: A good example can be found here. "],
["programming-paradigma-in-r.html", "2 Programming paradigma in R 2.1 Functional programming 2.2 Object-oriented programming", " 2 Programming paradigma in R TODO 2.1 Functional programming TODO purrr is a functional programming toolkit, much like the apply class of functions. However, purrr does so in a more unified way with consistent return values. Furthermore, in combination with magrittr, the code you write is naturally more concise and easier to read. library(&quot;purrr&quot;) library(&quot;ggplot2&quot;) library(&quot;gganimate&quot;) library(&quot;gapminder&quot;) library(&quot;repurrrsive&quot;) library(&quot;magrittr&quot;) library(DiagrammeR) utils::head(sw_people[[1]]) $name [1] &quot;Luke Skywalker&quot; $height [1] &quot;172&quot; $mass [1] &quot;77&quot; $hair_color [1] &quot;blond&quot; $skin_color [1] &quot;fair&quot; $eye_color [1] &quot;blue&quot; df &lt;- map_dfr(sw_people, .f = function(.) data.frame(color = .[[&quot;eye_color&quot;]], height = .[[&quot;height&quot;]], mass = .[[&quot;mass&quot;]])) utils::head(df) color height mass 1 blue 172 77 2 yellow 167 75 3 red 96 32 4 yellow 202 136 5 brown 150 49 6 blue 178 120 2.2 Object-oriented programming R has three different native ways for object-oriented programming and as far as I know one additional library. S3, S4 and refClasses (R5) come with the standard library, while R6 can be installed from CRAN. I actually never use R5, because it feels incredibly bulky and slow, so we will not cover it here. 2.2.1 S3 S3 methods dispatch on the first argument. If you come from other languages, such as Java, an S3 method is basically an overloaded function on the first argument. You can define an S3 function like this: s3 &lt;- function(x, y, ...) UseMethod(&quot;s3&quot;) s3.matrix &lt;- function(x, y, ...) apply(x, 1, sum) s3.character &lt;- function(x, y, ...) paste(x, y) s3(matrix(1:6, 2)) [1] 9 12 s3(&quot;hello&quot;, &quot;reader&quot;) [1] &quot;hello reader&quot; S3 classes are defines like this: s3.list &lt;- function(x, y, ...) { l &lt;- list(x = x, y = y) base::class(l) &lt;- &quot;my.s3&quot; l } s3(list(x = 1), y = 2) $x $x$x [1] 1 $y [1] 2 attr(,&quot;class&quot;) [1] &quot;my.s3&quot; The main issue here is of course that the user can easily overwrite a class and that method dispatching on one argument usually is not enough. However, often S3 functions are all you need. 2.2.2 S4 Bioconductor seems to prefer S4 over S3, so if you want to submit your package, you could for instance define interfaces using S4 and the rest using S3 or w/o OO entirely. In that way the user of your package only sees the exported interface (the S4 method) and upon calling would receive an S4 object. The rest of the implementation would be hidden. methods::setClass(&quot;normallist&quot;, representation = list(.el = &quot;list&quot;), prototype = methods::prototype(.el = list())) methods::setGeneric(&quot;put&quot;, function(obj, x) base::standardGeneric(&quot;insert&quot;)) methods::setMethod(&quot;put&quot;, signature = methods::signature(obj = &quot;normallist&quot;, x = &quot;vector&quot;), function(obj, x) obj@.el &lt;- as.list(x)) d &lt;- methods::new(&quot;normallist&quot;) d &lt;- put(d, seq(3)) 2.2.3 R5 2.2.4 R6 "],
["r-libraries.html", "3 R libraries 3.1 Data wrangling 3.2 Extending to C++ using Rcpp 3.3 Plotting 3.4 data.table 3.5 mlR and openML 3.6 Markdown and Shiny 3.7 Pryr 3.8 datastructures 3.9 Workflow management 3.10 Others", " 3 R libraries Much of R’s popularity is due to its fantastic ecosystem. R users benefit heavily from CRAN and Bioconductor packages created by its community. For data analysis or statistics R is a good choice for various reasons: high-level, easy to install packages, can be extended to C++ without needing knowledge of linking or C++ build-systems, probably the best plotting facility with ggplot, cowplot, hrbrthemes, ggsci and others, Bioconductor, machine learning and statistics libraries, small standard library. There are a few things, however, R is not so great at: in general slow, not really suited for large projects, poor object orientation, inconsistent function names, very limited threading capabilities. For stats, data analysis and writing reports I find R still superior to Python, partly due to Rmarkdown, shiny, ggplot2 and Rcpp. 3.1 Data wrangling Every analysis of data starts with preprocessing and parsing. For this I’ve found dplyr and tidyr tremendously useful. There are many more great tools in the tidyverse and Rstudio, such as purrr (explained later), magrittr or tibble, but these two simlify most of my work. library(dplyr) data(iris) group_by(iris, Species) %&gt;% summarize(Petal.Length = mean(Petal.Length), Sepal.Length = mean(Sepal.Length)) %&gt;% mutate(Species = toupper(Species)) # A tibble: 3 x 3 Species Petal.Length Sepal.Length &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; 1 SETOSA 1.46 5.01 2 VERSICOLOR 4.26 5.94 3 VIRGINICA 5.55 6.59 tidyr::gather(iris, Col, Val, -Species) %&gt;% head Species Col Val 1 setosa Sepal.Length 5.1 2 setosa Sepal.Length 4.9 3 setosa Sepal.Length 4.7 4 setosa Sepal.Length 4.6 5 setosa Sepal.Length 5.0 6 setosa Sepal.Length 5.4 3.2 Extending to C++ using Rcpp Using Rcpp (and RcppEigen, RcppArmadillo, Boost) you can easily your extend your code to C++. It not only nicely wraps the standard C API, but also let’s you use standard matrix libraries such as Eigen and Armadillo or Boost. If you have a project that’s not a package you can for instance create a function like this: Rcpp::cppFunction(&quot;double sum(std::vector&lt;double&gt;&amp; vec) { double sum = .0; for (std::vector&lt;double&gt;::size_type i = 0; i &lt; vec.size(); ++i) sum += vec[i]; return sum; }&quot;) sum(as.numeric(seq(10))) [1] 55 Let’s have a look at an Eigen example with sourceCpp: cat ./_src/square.cpp // [[Rcpp::depends(RcppEigen)]] #include &lt;RcppEigen.h&gt; // [[Rcpp::export]] Eigen::MatrixXd square(Eigen::MatrixXd&amp; m) { return m.transpose() * m; } library(&quot;RcppEigen&quot;) Rcpp::sourceCpp(&quot;./_src/square.cpp&quot;) square(matrix(rnorm(10), 2)) [,1] [,2] [,3] [,4] [,5] [1,] 1.1809514 1.3039481 -0.6709814 0.4204252 -1.9400934 [2,] 1.3039481 1.5176923 -0.4074778 0.2579352 -2.3642668 [3,] -0.6709814 -0.4074778 1.8073350 -1.1212513 0.1521923 [4,] 0.4204252 0.2579352 -1.1212513 0.6956308 -0.1028183 [5,] -1.9400934 -2.3642668 0.1521923 -0.1028183 3.8202198 Even for small matrices, the speed up is already substantial. m &lt;- matrix(rnorm(100 * 100), 100) microbenchmark::microbenchmark(square(m), t(m) %*% m) Unit: microseconds expr min lq mean median uq max neval square(m) 204.942 315.3105 727.458 440.8635 751.2425 4609.457 100 t(m) %*% m 694.202 883.4880 1846.186 1327.7880 1869.5325 15569.187 100 cld a b 3.2.1 Rcpp in a package Usually, you would want to put your source code into a cpp file in the src folder. Then you can call C++ from an R function, for instance as described below. Define a C++ source file and put it in src, like this: #include &lt;Rcpp.h&gt; // [[Rcpp::export]] Rcpp::List dostuff() { // some computations return Rcpp::List::create( Rcpp::Named(&quot;a&quot;) = ... ); } Add this to your DESCRIPTION: Imports: Rcpp LinkingTo: Rcpp Add a comment #' @useDynLib pkg, .registration = TRUE to the documentation of any function, better yet to the package doc. Call devtools::document() Call Rcpp::compileAttributes(&quot;./pkg&quot;) This should let you access the C++ function from your package. For more details check out the main documentation or some of my packages, like netReg or datastructures. The latter also has an example how to use modules and Boost. 3.2.2 Writing C++ Here are some tools that help you develop your code: gdb and lldb for debugging, valgrind and gprof to check for memory leaks and for profiling, Intel’s Parallel Studio XE (&lt;3) which is a toolbox for vectorization, debugging, memory checks, etc. If you can get hold of it, get it. It is magnificent. Boost for unit tests, data structures and basically everything you ever need, cppcheck for static code analysis, doxygen for code documentation. Many C++ libraries, like Dlib, Eigen or tensorflow have an R interface, so before implementing functionality yourself check out if there is already an implementation for it. At this point it also makes sense to have a look at various C++ books such as Scott Meyers: Effective Modern C++, Scott Meyers: Effective C++, Ben Klemens: 21. century C, Kurt Guntheroth: Optimized C++, Nicolai Josuttis: C++17 - the complete guide, David Vandevoorde: C++ Templates - the compete guide. For fast numerical code OpenMP and advanced vector and streaming SIMD extensions (AVX/SSE) is often the way to go. Writing good code using AVX is however not very simple and knowledge of memory alignment is required. However, starting from version 4 (?), OpenMP easily allows vectorization using #pragma simd. Note: the last lines in this section are heavily subjective and only state the author’s opinion. More and more garbage code is forced onto the scientific community, mostly related to academic hubris and lack of knowledge about how to program* (we don’t mean how to accomplish a task using a programming language, but to embrace a language and its philosophy at its very core). If you aim to publish your code, make sure it follows contemporary good practices, standards and guidelines and that it is consistent, for instance by following people’s code who are part of the community for ages. At this point we want to emphasize that the author doesn’t claim to know C++, but rather that he is annoyed by this very trend.* C++ is a large, complex language. Chances that you mess up, introduce bugs and memory leaks are high, unless you have some experience. In academia in mostly results in bad, un-maintainable code. If your argument is but it is faster than R, at least have a look at Fortran, Julia or Python (and numpy). If you still prefer hacking in C++ try to stick to some guidelines: don’t include C headers in your C++ projects .. just don’t. C and C++ are two languages. There is for need for FILE* or malloc. modern C++ rarely needs pointers. Use std::vector or std::unique_ptr. No need to manually release pointers is an advantage of itself. BOOST has (probably) everything you will ever need. Don’t reinvent the wheel and learn to include libraries in your project. Learn how to use Cmake, Meson or autotools. You should never need to directly invoke a compiler or write a hard-coded Makefile. Only because you have a PhD or M. Sc. in CS does not make you a prolific programmer. It requires staying up to date, reading other people’s code and embracing of new ideas and the very philosophy of the language and its community. Print warnings. They are usually there for a reason. Start a toy project or contribute to OSS projects. 3.3 Plotting One of the most significant reasons to use R is probably its plotting capabilities and people contributing to ggplot2 and the community’s effort of adding package that integrate with it. Some nice packages for plotting are the following: hrbrthemes ggthemes cowplot ggpubr ggthemr ggsci viridis and viridisLite colorspace and colorblindr highcharter patchwork animation plotly lattice magick imager scales tweenr ggraph, ggnet and ggnetwork gganimate and animattion 3.3.1 Layout Use hrbrthemes for a nicer layout: library(&quot;hrbrthemes&quot;) library(&quot;ggsci&quot;) import_roboto_condensed() g &lt;- ggplot(df) + geom_point(aes(x = height, y = mass, color = color)) + hrbrthemes::theme_ipsum_rc() + ggsci::scale_color_rickandmorty() print(g) Recently I started changing to simpler layouts and themes, for instance as described on Tufte in R. ggthemes offers some nice options to do so. For instance, if you are feeling jealous that you cannot draft some Excel plots, cause you are working with R: library(&quot;ggthemes&quot;) g &lt;- ggplot(df) + geom_point(aes(x = height, y = mass), color = &quot;green&quot;) + ggthemes::theme_excel() print(g) 3.3.2 Publication ready plots cowplot and ggpubr are great for greating publication ready plots: p1 &lt;- ggplot(mtcars, aes(hp, disp)) + geom_point() + ggthemes::theme_tufte() p2 &lt;- ggplot(mtcars, aes(hp, disp)) + geom_point() + ggthemes::theme_gdocs() cowplot::plot_grid(p1, p2, ncol = 2, align = &quot;vh&quot;, labels = c(&quot;Nice&quot;, &quot;Meh&quot;)) If these two are still not enough, I usually go with patchwork: library(patchwork) g + (p1 + p2) + plot_layout(ncol = 1) 3.3.3 Colors I use colorspace and colorblindr in order to remove some hue and chroma. viridis is a wonderful set of colors for continuous, sequential data. For discrete, qualitative data I mainly use ggthemr and the fresh colors. ggsci also has some wonderful color palettes. scales lets you have a look at a color palette easily. library(&quot;colorspace&quot;) library(&quot;colorblindr&quot;) library(&quot;viridis&quot;) library(&quot;ggthemr&quot;) library(&quot;scales&quot;) library(&quot;cowplot&quot;) ggthemr::ggthemr(&quot;fresh&quot;, &quot;scientific&quot;, spacing = 2, type = &quot;inner&quot;) p1 &lt;- colorblindr::gg_color_gradient() + colorspace::scale_fill_continuous_sequential(&quot;viridis&quot;, c1 = 20, c2 = 70, l1 = 25, l2 = 100) p2 &lt;- colorblindr::gg_color_gradient() + colorspace::scale_fill_continuous_sequential(&quot;Blues&quot;, c1 = 20, c2 = 70, l1 = 25, l2 = 100) p3 &lt;- colorblindr::gg_color_gradient() + colorspace::scale_fill_continuous_diverging(c1 = 40) df &lt;- data.frame(Col = ggthemr::swatch()[1:10], X = 1, Y = seq(10)) p4 &lt;- ggplot(df) + geom_tile(aes(x = Y, y = X), fill = df$Col) + theme_void() cowplot::plot_grid(p1, p2, p3, p4, ncol = 2, align = &quot;vh&quot;) Another great tool is swatches: library(swatches) omega_nebula &lt;- read_ase(system.file(&quot;palettes&quot;, &quot;omega_nebula.ase&quot;, package = &quot;swatches&quot;)) show_palette(omega_nebula) 3.3.4 Interactive and animated plots Often you want to create an interactive plot, for instance when serving on a shiny instance. One way to do that is using plotly: library(&quot;plotly&quot;) q &lt;- qplot(data = iris, x = Sepal.Length, y = Sepal.Width, color = Species) + ggthemes::theme_tufte() plotly::ggplotly(q) Recently I also stumbled upon highcharter and ggvis: library(&quot;highcharter&quot;) hchart(iris, &quot;scatter&quot;, hcaes(x = Sepal.Length, y = Sepal.Width, group = Species)) %&gt;% hc_add_theme(hc_theme_tufte()) library(&quot;ggvis&quot;) data(&quot;mtcars&quot;) mtcars %&gt;% ggvis(~wt, ~mpg, `:=`(size, input_slider(10, 100)), `:=`(opacity, input_slider(0, 1))) %&gt;% layer_points() Renderer: SVG | Canvas Download With gganimate you can directly create GIFs from you plots: library(&quot;gganimate&quot;) library(&quot;gapminder&quot;) g &lt;- ggplot(gapminder, aes(gdpPercap, lifeExp, size = pop, frame = year)) + geom_point() + geom_smooth(aes(group = year), method = &quot;lm&quot;, show.legend = FALSE) + facet_wrap(~continent, scales = &quot;free&quot;) + ggthemes::theme_tufte() gganimate(g) 3.3.5 Graphs There are many wonderful graph and network libraries around. I primarily use ggnetwork/ggnet2, igraph, ggraph and DiagrammeR. library(DiagrammeR) create_graph() %&gt;% add_node(label = expression(Z), node_aes = node_aes(penwidth = 2, fontname = &quot;Arial Narrow&quot;, fontcolor = &quot;black&quot;, fillcolor = &quot;white&quot;, color = &quot;black&quot;)) %&gt;% add_node(label = &quot;X&quot;, node_aes = node_aes(penwidth = 2, fontname = &quot;Arial Narrow&quot;, fontcolor = &quot;black&quot;, fillcolor = &quot;grey&quot;, color = &quot;black&quot;)) %&gt;% add_edge(from = 1, to = 2, edge_aes = edge_aes(color = &quot;black&quot;)) %&gt;% render_graph(layout = &quot;tree&quot;) 3.4 data.table data.table is a fast implementation of R’s classical data.frame. I hardly ever use data frame any more, and if so only, because it seems to work nicer with dplyr and tidyr. However, by using dtplyr this isn’t much of a problem, really. library(&quot;data.table&quot;) library(&quot;dplyr&quot;) library(&quot;dtplyr&quot;) library(&quot;grid&quot;) library(&quot;gridExtra&quot;) n &lt;- 1000 rn &lt;- stats::rnorm(n) ltrs &lt;- base::sample(letters[1:5], n, replace = TRUE) dt &lt;- data.table::data.table(X = rn, Y = ltrs) df &lt;- base::data.frame(X = rn, Y = ltrs) dt[, .SD[sample(.N, 1)], by = c(&quot;Y&quot;)] %&gt;% tableGrob(rows = NULL) %&gt;% grid.arrange In the end it depends what style you prefer. I usually go with data.table alone without needing the dplyr/dtplyr dependency. However, the latter is usually more readable. For large data, the fastest solution is probably preferable. dt.only &lt;- function() dt[, .SD[sample(.N, 1)], by = c(&quot;Y&quot;)] dt.dtplyr &lt;- function() dt %&gt;% dplyr::group_by(Y) %&gt;% dplyr::sample_n(1) df.dplyr &lt;- function() df %&gt;% dplyr::group_by(Y) %&gt;% dplyr::sample_n(1) microbenchmark::microbenchmark(dt.only(), dt.dtplyr(), df.dplyr()) Unit: milliseconds expr min lq mean median uq max neval dt.only() 1.627221 1.775081 2.059207 1.906559 2.112410 5.201621 100 dt.dtplyr() 2.421354 2.683622 3.172868 2.813725 3.061799 14.350918 100 df.dplyr() 1.525751 1.715917 1.986308 1.832446 1.995918 5.039091 100 cld a b a 3.5 mlR and openML CRAN offers dozens of packages related to machine and statistical learning, many of which doing the same. mlR wraps many of these into one big library. mlR integrates with openML, an open machine learning platform where people share code, data and algorithms. Here we show an example where we use a Gaussian process to predict the Kyphosis label from the gam package. library(mlr) task &lt;- mlr::makeClassifTask(data = kyphosis, target = &quot;Kyphosis&quot;) lrn &lt;- mlr::makeLearner(&quot;classif.gausspr&quot;) n &lt;- nrow(kyphosis) train.set &lt;- sample(n, size = 2/3 * n) test.set &lt;- setdiff(1:n, train.set) model &lt;- mlr::train(lrn, task, subset = train.set) Using automatic sigma estimation (sigest) for RBF or laplace kernel pred &lt;- stats::predict(model, task = task, subset = test.set) performance(pred, measures = list(mmce, acc)) mmce acc 0.2592593 0.7407407 3.6 Markdown and Shiny Rmarkdown is a great way for documentation, reporting and working reproducibly. Rstudio provides tons of different output formats like web sites (like this one), Tufte style documents, blogs and others. If you want to present your work interactively you can do so by building a web page using shiny. For presentations that use R code I use either xaringan, Slidify or reveal.js. Find all the output formats by Rstudio here. 3.6.1 Shiny Setting up a Shiny instance for reporting is a great way to present data using interactive plots. Setting up shiny is fairly easy. You need to create a server.R file and ui.R file, e.g. like this: cat R/ui.R library(shiny) library(shinyjs) library(plotly) shinyUI( fluidPage( useShinyjs(), fluidRow( column( width = 6,offset=2, h3(&quot;Scatterplot&quot;), HTML(&quot;&lt;h5&gt;&lt;i&gt;Created using ggplot2, hrbrthemes and ggsci on the iris data.&lt;/i&gt;&lt;/h5&gt;&quot;), plotOutput(&quot;scatterplot&quot;, width=800) ) ) ) ) cat R/ui.R library(shiny) library(shinyjs) library(plotly) shinyUI( fluidPage( useShinyjs(), fluidRow( column( width = 6,offset=2, h3(&quot;Scatterplot&quot;), HTML(&quot;&lt;h5&gt;&lt;i&gt;Created using ggplot2, hrbrthemes and ggsci on the iris data.&lt;/i&gt;&lt;/h5&gt;&quot;), plotOutput(&quot;scatterplot&quot;, width=800) ) ) ) ) You can publish your server on shinyapps.io so that it is accessible by everyone. 3.7 Pryr In some cases it is interesting to have a look at the implementation of specific functions, get their sizes in byte or get the current memory consumption. It is especially useful to keep track of the addresses your objects point to. When I was new to R I found it confusing when a reference is dropped and when a new copy of an object is created. library(&quot;pryr&quot;) pryr::inspect(list()) &lt;VECSXP 0x7fcce395cba8&gt; pryr::inspect(vector()) &lt;LGLSXP 0x7fcce407dd90&gt; pryr::object_size(numeric()) 48 B pryr::object_size(numeric(1)) 56 B x &lt;- stats::rnorm(10) y &lt;- x pryr::address(x) [1] &quot;0x7fccc8393648&quot; pryr::address(y) [1] &quot;0x7fccc8393648&quot; y[1] &lt;- 1 pryr::address(y) [1] &quot;0x7fccc838a4b8&quot; 3.8 datastructures If you have a background in computer science you may wonder, that R does not have support for advanced data structures such as Fibonacci heaps or hashmaps. datastructures tries to solve this. It uses Rcpp modules to export Boost data structures to R: library(&quot;datastructures&quot;) q &lt;- datastructures::fibonacci_heap(&quot;integer&quot;) q[1:3] &lt;- list(rnorm(3), 2, rnorm(4)) datastructures::pop(q) $`1` [1] -0.5581804 -1.0901567 -1.0550364 datastructures::pop(q) $`2` [1] 2 datastructures::pop(q) $`3` [1] -0.190276198 -0.003941753 -1.434193519 0.868626929 datastructures::pop(q) NULL 3.9 Workflow management I recently came across drake as a workflow manager. It allows you to run a project and easily update output files. 3.10 Others There are many other great tools I did not specifically mention due to the fact that they are probably more situational. Some of these are: rlang argparse, IRKernel, CVXR, minqa and nloptr, tensorflow and keras, glmnet, lme4 and netReg. "],
["good-practices.html", "4 Good practices 4.1 Continuous integration 4.2 Version control 4.3 Docker 4.4 Code style", " 4 Good practices Continuous integration, version control and containerization are three of the many tools of a developer. Here, I quickly introduce how the three can be used for R. 4.1 Continuous integration To be honest, doing all the steps from the section above is tedious and annoying. For that reason I set up Travis CI to take care of running our tests, static analysis and code coverage in the project. Travis works for Mac and Unix. cat ./pkg/.travis.yml language: r sudo: required dist: trusty cache: packages matrix: include: - compiler: gcc addons: apt: sources: - ubuntu-toolchain-r-test packages: - g++-5 env: COMPILER=g++-5 - compiler: clang addons: apt: sources: - ubuntu-toolchain-r-test - llvm-toolchain-precise-3.7 packages: - clang-3.7 env: COMPILER=clang++-3.7 env: global: - R_BUILD_ARGS=&quot;--no-build-vignettes --no-manual&quot; - R_CHECK_ARGS=&quot;--no-build-vignettes --no-manual --as-cran&quot; - LINTR_COMMENT_BOT=false before_install: - cd newpkg r_packages: - covr - testthat - lintr after_script: - tar -C .. -xf $PKG_TARBALL - Rscript -e &#39;covr::codecov()&#39; - Rscript -e &#39;lintr::lint_package()&#39; Check out Travis’ docs for more info. What we are basically telling Travis to do is to check our package --as-cran, run the unit tests, do the code coverage and finally do a static code analysis. In order to do the same for Windows machines, we also use AppVeyor. cat ./pkg/appveyor.yml # DO NOT CHANGE the &quot;init&quot; and &quot;install&quot; sections below # Download script file from GitHub init: ps: | $ErrorActionPreference = &quot;Stop&quot; Invoke-WebRequest http://raw.github.com/krlmlr/r-appveyor/master/scripts/appveyor-tool.ps1 -OutFile &quot;..\\appveyor-tool.ps1&quot; Import-Module &#39;..\\appveyor-tool.ps1&#39; install: ps: Bootstrap # Adapt as necessary starting from here before_build: ps: cd newpkg build_script: - ps: cd newpkg - travis-tool.sh install_deps test_script: - travis-tool.sh run_tests on_failure: - 7z a failure.zip *.Rcheck\\* - appveyor PushArtifact failure.zip artifacts: - path: &#39;*.Rcheck\\**\\*.log&#39; name: Logs - path: &#39;*.Rcheck\\**\\*.out&#39; name: Logs - path: &#39;*.Rcheck\\**\\*.fail&#39; name: Logs - path: &#39;*.Rcheck\\**\\*.Rout&#39; name: Logs - path: &#39;\\*_*.tar.gz&#39; name: Bits - path: &#39;\\*_*.zip&#39; name: Bits Here, we only run some tests and checks, since we already got the code analysis and coverage. Code coverage of our project yielded us the following results: Code coverage If we check the travis log, we see it has succeeded, because all tests ran through. However, we have some lints we should fix. $ tar -C .. -xf $PKG_TARBALL after_script.2 2.22s$ Rscript -e 'covr::codecov()' $message [1] \"Coverage reports upload successfully\" $id [1] \"552fd0db-187b-434e-b37b-a0e4fcba7636\" $meta $meta$status [1] 200 $queued [1] TRUE $url [1] \"https://codecov.io/github/dirmeier/essential-R/commit/f24d277296f78512524f26f3ca3b31d202e122a1\" $uploaded [1] TRUE after_script.3 1.23s$ Rscript -e 'lintr::lint_package()' R/bad_bad_file.R:3:1: style: lines should not be more than 80 characters. myRet = a+b ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ R/bad_bad_file.R:3:79: style: Variable and function names should be all lowercase. myRet = a+b ^~~~~ R/bad_bad_file.R:3:85: style: Use Fixing style related issues is essential since we want other people to be able to read our code easily. Good code also increases the number of users, because the package is more trusted than a spaghetti code package. Beauty is more important in computing than anywhere else in technology because software is so complicated. Beauty is the ultimate defense against complexity. – David Gelernter 4.2 Version control Aside from he fact that version control is great, putting your project on GitHub has the most prominent advantage that you can add badges to your README.md to show others about the state of your package, for instance repository, CI or code coverage status. There’s a wide variety of badges to describe your project. Description Badge Is the project passing on windows? How long is it on Bioconductor? Is it installable using conda? What is its version on CRAN? How often has it been downloaded? 4.3 Docker todo (needed for debugging c++) 4.4 Code style I try to follow two general guidelines when writing code. These are primarily not my personal preferences, nut adopted form packages like data.table, lme4, Matrix or Bioconductor. Whatever you do, just be consistent. There seem to be a lot of different preference around. If I mainly write using S3 classes and functions I prefer writing code like this: my.var &lt;- &quot;2&quot; i.am.a.function &lt;- function(i) { sapply(seq(10), function(i) { i + 1 }) } plot.me &lt;- function(x, ...) plot.default(x) .i.am.private &lt;- &quot;2&quot; For S4 classes and functions I recommend using the Bioconductor style guide or how lme4 and Matrix do it: setMethod(&quot;camelCaps&quot;, signature = signature(iAmAList = &quot;list&quot;)) "]
]
